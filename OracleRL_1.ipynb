{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMb7bmfbqVutnSlvNoaZZs8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarettGazay/ai_projects/blob/master/OracleRL_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym\n",
        "!pip install stable_baselines3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ges_w2kWuMA",
        "outputId": "8804228d-0eb5-4485-e60e-4b75ea9f0fc5"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.8/dist-packages (0.21.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym) (2.2.1)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym) (1.22.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: stable_baselines3 in /usr/local/lib/python3.8/dist-packages (1.7.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from stable_baselines3) (1.3.5)\n",
            "Requirement already satisfied: importlib-metadata~=4.13 in /usr/local/lib/python3.8/dist-packages (from stable_baselines3) (4.13.0)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.8/dist-packages (from stable_baselines3) (1.13.1+cu116)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from stable_baselines3) (2.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from stable_baselines3) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from stable_baselines3) (3.5.3)\n",
            "Requirement already satisfied: gym==0.21 in /usr/local/lib/python3.8/dist-packages (from stable_baselines3) (0.21.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata~=4.13->stable_baselines3) (3.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch>=1.11->stable_baselines3) (4.5.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable_baselines3) (4.38.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable_baselines3) (23.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable_baselines3) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable_baselines3) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable_baselines3) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable_baselines3) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.8/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->stable_baselines3) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "ZCyChxNzeEM4"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/training_data.csv')"
      ],
      "metadata": {
        "id": "qbs8dBKhYyIm"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "LBqxI7cIY9YN",
        "outputId": "c6c4e650-c949-43c5-d077-9d73e70deae4"
      },
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    appt_hour  appt_minute  asset_id  dropoff_lat  dropoff_lng  load_order  \\\n",
              "0           5            0         0  -121.848076    37.360374           1   \n",
              "1           5           45         0  -121.931480    37.311272           0   \n",
              "2           6           15         0  -121.933708    37.315559           0   \n",
              "3           7           45         0  -122.203010    37.485722           0   \n",
              "4           9           15         0  -122.093407    37.398567           0   \n",
              "5          10           30         0  -121.891464    37.245495           0   \n",
              "6           0            0         0  -121.964226    37.292717           0   \n",
              "7           0            0         0  -121.961914    37.275314           0   \n",
              "8           5           45         1  -122.079163    37.382942           0   \n",
              "9           6           45         1  -121.891701    37.245491           0   \n",
              "10          7           30         1  -121.979050    37.322437           0   \n",
              "11          8           45         1  -121.994743    37.336449           0   \n",
              "12          9           30         1  -121.950935    37.255798           0   \n",
              "13          0            0         1  -121.891289    37.314491           0   \n",
              "14         11            0         1  -121.979034    37.322464           0   \n",
              "\n",
              "    multi_load_after  multi_load_before  pickup_hour  pickup_lat  pickup_lng  \\\n",
              "0                  0                  0            4 -121.818245   37.319942   \n",
              "1                  0                  0            5 -121.891289   37.314491   \n",
              "2                  0                  0            5 -121.964226   37.292717   \n",
              "3                  0                  0            6 -122.018349   37.353180   \n",
              "4                  0                  0            8 -122.163383   37.477654   \n",
              "5                  0                  0            9 -121.950905   37.334362   \n",
              "6                  0                  0            9 -121.933708   37.315559   \n",
              "7                  0                  0           10 -121.891701   37.245491   \n",
              "8                  0                  0            4 -122.026657   37.321224   \n",
              "9                  0                  0            5 -121.961914   37.275314   \n",
              "10                 0                  0            6 -121.975922   37.313007   \n",
              "11                 0                  0            7 -122.158218   37.450043   \n",
              "12                 0                  0            8 -121.923241   37.303089   \n",
              "13                 0                  0            9 -121.931480   37.311272   \n",
              "14                 0                  0           10 -121.967812   37.322025   \n",
              "\n",
              "    pickup_minute  rider_id  schedule_order  space_type  \n",
              "0              15        43               0           5  \n",
              "1               0        25               1           5  \n",
              "2              30        19               2           5  \n",
              "3              45        46               3           5  \n",
              "4              15        24               4           5  \n",
              "5              30        21               5           5  \n",
              "6              45        19               6           5  \n",
              "7              30        10               7           1  \n",
              "8              45         2               8           5  \n",
              "9              45        10               9           1  \n",
              "10             45        28              10           5  \n",
              "11             45         6              11           0  \n",
              "12             45        13              12           5  \n",
              "13             30        25              13           5  \n",
              "14             30        16              14           5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f85858fe-afb3-47d0-8fde-e698f753bd07\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>appt_hour</th>\n",
              "      <th>appt_minute</th>\n",
              "      <th>asset_id</th>\n",
              "      <th>dropoff_lat</th>\n",
              "      <th>dropoff_lng</th>\n",
              "      <th>load_order</th>\n",
              "      <th>multi_load_after</th>\n",
              "      <th>multi_load_before</th>\n",
              "      <th>pickup_hour</th>\n",
              "      <th>pickup_lat</th>\n",
              "      <th>pickup_lng</th>\n",
              "      <th>pickup_minute</th>\n",
              "      <th>rider_id</th>\n",
              "      <th>schedule_order</th>\n",
              "      <th>space_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-121.848076</td>\n",
              "      <td>37.360374</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>-121.818245</td>\n",
              "      <td>37.319942</td>\n",
              "      <td>15</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>-121.931480</td>\n",
              "      <td>37.311272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>-121.891289</td>\n",
              "      <td>37.314491</td>\n",
              "      <td>0</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>-121.933708</td>\n",
              "      <td>37.315559</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>-121.964226</td>\n",
              "      <td>37.292717</td>\n",
              "      <td>30</td>\n",
              "      <td>19</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>45</td>\n",
              "      <td>0</td>\n",
              "      <td>-122.203010</td>\n",
              "      <td>37.485722</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>-122.018349</td>\n",
              "      <td>37.353180</td>\n",
              "      <td>45</td>\n",
              "      <td>46</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>-122.093407</td>\n",
              "      <td>37.398567</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>-122.163383</td>\n",
              "      <td>37.477654</td>\n",
              "      <td>15</td>\n",
              "      <td>24</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>10</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>-121.891464</td>\n",
              "      <td>37.245495</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>-121.950905</td>\n",
              "      <td>37.334362</td>\n",
              "      <td>30</td>\n",
              "      <td>21</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-121.964226</td>\n",
              "      <td>37.292717</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>-121.933708</td>\n",
              "      <td>37.315559</td>\n",
              "      <td>45</td>\n",
              "      <td>19</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-121.961914</td>\n",
              "      <td>37.275314</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>-121.891701</td>\n",
              "      <td>37.245491</td>\n",
              "      <td>30</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>-122.079163</td>\n",
              "      <td>37.382942</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>-122.026657</td>\n",
              "      <td>37.321224</td>\n",
              "      <td>45</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>6</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>-121.891701</td>\n",
              "      <td>37.245491</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>-121.961914</td>\n",
              "      <td>37.275314</td>\n",
              "      <td>45</td>\n",
              "      <td>10</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>7</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>-121.979050</td>\n",
              "      <td>37.322437</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>-121.975922</td>\n",
              "      <td>37.313007</td>\n",
              "      <td>45</td>\n",
              "      <td>28</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>8</td>\n",
              "      <td>45</td>\n",
              "      <td>1</td>\n",
              "      <td>-121.994743</td>\n",
              "      <td>37.336449</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>-122.158218</td>\n",
              "      <td>37.450043</td>\n",
              "      <td>45</td>\n",
              "      <td>6</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>9</td>\n",
              "      <td>30</td>\n",
              "      <td>1</td>\n",
              "      <td>-121.950935</td>\n",
              "      <td>37.255798</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>-121.923241</td>\n",
              "      <td>37.303089</td>\n",
              "      <td>45</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-121.891289</td>\n",
              "      <td>37.314491</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>-121.931480</td>\n",
              "      <td>37.311272</td>\n",
              "      <td>30</td>\n",
              "      <td>25</td>\n",
              "      <td>13</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>-121.979034</td>\n",
              "      <td>37.322464</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>-121.967812</td>\n",
              "      <td>37.322025</td>\n",
              "      <td>30</td>\n",
              "      <td>16</td>\n",
              "      <td>14</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f85858fe-afb3-47d0-8fde-e698f753bd07')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f85858fe-afb3-47d0-8fde-e698f753bd07 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f85858fe-afb3-47d0-8fde-e698f753bd07');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "metadata": {
        "id": "TqHQf5hWWTat"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from stable_baselines3 import PPO"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box\n",
        "import numpy as np\n",
        "\n",
        "class OracleEnv(Env):\n",
        "    metadata = {'render.modes': ['human']}\n",
        "    def __init__(self, \n",
        "        data,\n",
        "        schedule_order,\n",
        "        space_type_encoder,\n",
        "        rider_id_encoder,\n",
        "        asset_id_encoder,\n",
        "        num_samples):\n",
        "\n",
        "        self.data = data\n",
        "        self.schedule_order = schedule_order\n",
        "        self.space_type_encoder = space_type_encoder # to decode after prediction\n",
        "        self.rider_id_encoder = rider_id_encoder # to decode after prediction\n",
        "        self.asset_id_encoder = asset_id_encoder # to decode after prediction\n",
        "\n",
        "        self.state = None\n",
        "        self.selected_index = 0 # zero at start\n",
        "        self.selected_ride = None\n",
        "        self.num_features = 15\n",
        "        self.num_samples = num_samples\n",
        "        self.last_obs = None\n",
        "\n",
        "        self.schedule_position_indexer = 0 # represents the ride-schedule positional relationship in time\n",
        "        # that we want the agent to predict for, increments each time an action is taken, \n",
        "        # if the agent does not select the ride with the corresponding load order that matches this number,\n",
        "        # it will end in a terminal state where the agent will get a negative reward. \n",
        "\n",
        "\n",
        "        self.action_space = Discrete(3)\n",
        "        self.observation_space = Box(low=-np.inf, high=np.inf, shape=(self.num_features,))\n",
        "\n",
        "    def step(self, action):\n",
        "        info = {}\n",
        "\n",
        "        # Apply action\n",
        "        if action == 0 and self.selected_index > 0: # move up\n",
        "            self.selected_index -= 1\n",
        "            self.state = self.data[self.selected_index]\n",
        "\n",
        "        elif action == 1 and self.selected_index <= self.num_samples: # move down \n",
        "            self.selected_index += 1\n",
        "            try: self.state = self.data[self.selected_index] # if the agent tries to move outside the boundaries of the bottom end of the list end the game\n",
        "              \n",
        "            except: \n",
        "              reward = -1 # punish for going out of bounds - may not be necessary\n",
        "              done = True\n",
        "\n",
        "        elif action == 2: # select current ride\n",
        "            self.state = self.data[self.selected_index] # select the state using agent's selected index\n",
        "        else:\n",
        "            self.selected_index = 0 # Agent selects the starting point state if it tries to move up at starting point which would end in a negative number which is invalid.\n",
        "        \n",
        "        # Calculate Reward\n",
        "        if self.state[13] == self.schedule_position_indexer: # if the agent selected the correct ride for the SPI - self.state[13] is the schedule order.\n",
        "\n",
        "            reward = 1 \n",
        "            done = False # Good job agent, you may continue the game.\n",
        "            # print(f'Agent selected the correct ride for the SPI - Agent selection index: {self.selected_index} == SPI: {self.schedule_position_indexer} ')\n",
        "        else: \n",
        "            reward = -1 # if the agent selects the wrong index to SPI relationship.\n",
        "            done = True # Terminal state for failing to order correctly - The agent must put every ride in the correct order or the schedeule will have not been made correctly and the hard and fast goal is to get the agent to learn how to arrange a schedule like the human did.\n",
        "        \n",
        "        # Check if ordering is done\n",
        "        if self.schedule_position_indexer == self.num_samples: \n",
        "            done = True\n",
        "            reward = 100 # if the agent gets to the end it means it has selected the correct schedule so it gets a fatty reward.\n",
        "        \n",
        "        # Return step information\n",
        "        self.schedule_position_indexer += 1\n",
        "\n",
        "        # Mask features to help the agent learn from the critical features.\n",
        "        masked_observation = np.copy(self.state) # ensure that the original observation is not modified when masking the feature.\n",
        "        masked_observation[13] = -1 # Mask the third feature of the observation by setting its value to -1\n",
        "        # print(masked_observation)\n",
        "        return masked_observation, reward, done, info\n",
        "\n",
        "    def render(self):\n",
        "        # Implement viz\n",
        "        pass\n",
        "    \n",
        "    def reset(self):\n",
        "        # Reset shower temperature\n",
        "        self.state = self.data[0] # index zero of the observation space\n",
        "        self.selected_index = 0\n",
        "        self.schedule_position_indexer = 0 # start iteration from the beginning\n",
        "        return self.state\n",
        "\n",
        "    def last_obs(self):\n",
        "      return self.last_obs\n"
      ],
      "metadata": {
        "id": "6qfyshnpWcU2"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # Label encode \n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "space_type_encoder = LabelEncoder() \n",
        "space_type_encoder.fit_transform(data['space_type'])\n",
        "\n",
        "rider_id_encoder = LabelEncoder()\n",
        "rider_id_encoder.fit_transform(data['rider_id'])\n",
        "\n",
        "asset_id_encoder = LabelEncoder()\n",
        "asset_id_encoder.fit_transform(data['asset_id'])\n",
        "\n",
        "schedule_order = [x for x in data['schedule_order']]\n",
        "num_samples = len(data)"
      ],
      "metadata": {
        "id": "kNlvTJi5aMG5"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the environment\n",
        "env = OracleEnv(\n",
        "    data.values,\n",
        "    schedule_order,\n",
        "    space_type_encoder,\n",
        "    rider_id_encoder,\n",
        "    asset_id_encoder,\n",
        "    num_samples)"
      ],
      "metadata": {
        "id": "ukcy4nAYZ_rc"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "env = DummyVecEnv([lambda: env])  # Create a vectorized environment\n",
        "\n",
        "model = PPO('MlpPolicy', env, verbose=1)  # Create a PPO model\n",
        "\n",
        "model.learn(total_timesteps=1000000)  # Train the model for 10000 timesteps\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6obLYzBiT2DP",
        "outputId": "1ddb4a0c-41ad-439f-909e-0583a6ef43aa"
      },
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "-----------------------------\n",
            "| time/              |      |\n",
            "|    fps             | 667  |\n",
            "|    iterations      | 1    |\n",
            "|    time_elapsed    | 3    |\n",
            "|    total_timesteps | 2048 |\n",
            "-----------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 583         |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 7           |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.035243846 |\n",
            "|    clip_fraction        | 0.199       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -1.08       |\n",
            "|    explained_variance   | -0.000473   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.349       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0543     |\n",
            "|    value_loss           | 1.05        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 529        |\n",
            "|    iterations           | 3          |\n",
            "|    time_elapsed         | 11         |\n",
            "|    total_timesteps      | 6144       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06782349 |\n",
            "|    clip_fraction        | 0.368      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.942     |\n",
            "|    explained_variance   | -0.0158    |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.46       |\n",
            "|    n_updates            | 20         |\n",
            "|    policy_gradient_loss | -0.0843    |\n",
            "|    value_loss           | 2.49       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 409         |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 19          |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.049412645 |\n",
            "|    clip_fraction        | 0.257       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.662      |\n",
            "|    explained_variance   | 0.02        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 4.99        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0656     |\n",
            "|    value_loss           | 7.06        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 426         |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 24          |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017447395 |\n",
            "|    clip_fraction        | 0.208       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.46       |\n",
            "|    explained_variance   | 0.0544      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.83        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0481     |\n",
            "|    value_loss           | 13          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 431         |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 28          |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018568467 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.33       |\n",
            "|    explained_variance   | 0.0876      |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.4        |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0327     |\n",
            "|    value_loss           | 15.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 443         |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 32          |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008238532 |\n",
            "|    clip_fraction        | 0.0701      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.242      |\n",
            "|    explained_variance   | 0.235       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.7        |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0222     |\n",
            "|    value_loss           | 15.9        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 453         |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 36          |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014791123 |\n",
            "|    clip_fraction        | 0.0667      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.181      |\n",
            "|    explained_variance   | 0.249       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.9        |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0106     |\n",
            "|    value_loss           | 22.5        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 455          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 40           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0043881917 |\n",
            "|    clip_fraction        | 0.0252       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.144       |\n",
            "|    explained_variance   | 0.286        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 11           |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.0031      |\n",
            "|    value_loss           | 26.9         |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 462        |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 44         |\n",
            "|    total_timesteps      | 20480      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00327641 |\n",
            "|    clip_fraction        | 0.0211     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.127     |\n",
            "|    explained_variance   | 0.404      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 12.4       |\n",
            "|    n_updates            | 90         |\n",
            "|    policy_gradient_loss | -0.0052    |\n",
            "|    value_loss           | 30.4       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 468         |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 48          |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004831504 |\n",
            "|    clip_fraction        | 0.0185      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.108      |\n",
            "|    explained_variance   | 0.581       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.37        |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00554    |\n",
            "|    value_loss           | 25.1        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 467          |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 52           |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041641756 |\n",
            "|    clip_fraction        | 0.0185       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0875      |\n",
            "|    explained_variance   | 0.686        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 10.5         |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.00211     |\n",
            "|    value_loss           | 20.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 471          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 56           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0050602425 |\n",
            "|    clip_fraction        | 0.014        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0771      |\n",
            "|    explained_variance   | 0.703        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.83         |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.0105      |\n",
            "|    value_loss           | 21.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 475          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 60           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033428003 |\n",
            "|    clip_fraction        | 0.018        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0673      |\n",
            "|    explained_variance   | 0.781        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.79         |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | 0.00358      |\n",
            "|    value_loss           | 15.9         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 474           |\n",
            "|    iterations           | 15            |\n",
            "|    time_elapsed         | 64            |\n",
            "|    total_timesteps      | 30720         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00096459745 |\n",
            "|    clip_fraction        | 0.00635       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0497       |\n",
            "|    explained_variance   | 0.87          |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.32          |\n",
            "|    n_updates            | 140           |\n",
            "|    policy_gradient_loss | -0.00517      |\n",
            "|    value_loss           | 9.72          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 477          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 68           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022452178 |\n",
            "|    clip_fraction        | 0.00801      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0471      |\n",
            "|    explained_variance   | 0.923        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.356        |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | 0.0117       |\n",
            "|    value_loss           | 5.96         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 480         |\n",
            "|    iterations           | 17          |\n",
            "|    time_elapsed         | 72          |\n",
            "|    total_timesteps      | 34816       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004692942 |\n",
            "|    clip_fraction        | 0.00522     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0397     |\n",
            "|    explained_variance   | 0.903       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.3         |\n",
            "|    n_updates            | 160         |\n",
            "|    policy_gradient_loss | -0.00818    |\n",
            "|    value_loss           | 8.12        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 479           |\n",
            "|    iterations           | 18            |\n",
            "|    time_elapsed         | 76            |\n",
            "|    total_timesteps      | 36864         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00032518775 |\n",
            "|    clip_fraction        | 0.00317       |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0349       |\n",
            "|    explained_variance   | 0.964         |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.649         |\n",
            "|    n_updates            | 170           |\n",
            "|    policy_gradient_loss | -0.00352      |\n",
            "|    value_loss           | 2.77          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 481          |\n",
            "|    iterations           | 19           |\n",
            "|    time_elapsed         | 80           |\n",
            "|    total_timesteps      | 38912        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0007384927 |\n",
            "|    clip_fraction        | 0.00469      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0335      |\n",
            "|    explained_variance   | 0.974        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.111        |\n",
            "|    n_updates            | 180          |\n",
            "|    policy_gradient_loss | 0.0167       |\n",
            "|    value_loss           | 2.24         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 484         |\n",
            "|    iterations           | 20          |\n",
            "|    time_elapsed         | 84          |\n",
            "|    total_timesteps      | 40960       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001205012 |\n",
            "|    clip_fraction        | 0.00928     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0256     |\n",
            "|    explained_variance   | 0.993       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.0438      |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | 0.00388     |\n",
            "|    value_loss           | 0.522       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 477          |\n",
            "|    iterations           | 21           |\n",
            "|    time_elapsed         | 89           |\n",
            "|    total_timesteps      | 43008        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030305274 |\n",
            "|    clip_fraction        | 0.0197       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0386      |\n",
            "|    explained_variance   | 0.995        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 0.461        |\n",
            "|    n_updates            | 200          |\n",
            "|    policy_gradient_loss | -0.00204     |\n",
            "|    value_loss           | 0.506        |\n",
            "------------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 479       |\n",
            "|    iterations           | 22        |\n",
            "|    time_elapsed         | 93        |\n",
            "|    total_timesteps      | 45056     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.3309906 |\n",
            "|    clip_fraction        | 0.0784    |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.014    |\n",
            "|    explained_variance   | 0.689     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 6.12      |\n",
            "|    n_updates            | 210       |\n",
            "|    policy_gradient_loss | -0.0241   |\n",
            "|    value_loss           | 19.2      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 481       |\n",
            "|    iterations           | 23        |\n",
            "|    time_elapsed         | 97        |\n",
            "|    total_timesteps      | 47104     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 2.6661654 |\n",
            "|    clip_fraction        | 0.838     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.622    |\n",
            "|    explained_variance   | -0.283    |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 7.67      |\n",
            "|    n_updates            | 220       |\n",
            "|    policy_gradient_loss | -0.0383   |\n",
            "|    value_loss           | 25.6      |\n",
            "---------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 480           |\n",
            "|    iterations           | 24            |\n",
            "|    time_elapsed         | 102           |\n",
            "|    total_timesteps      | 49152         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00064132677 |\n",
            "|    clip_fraction        | 0.0043        |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0223       |\n",
            "|    explained_variance   | 0.371         |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.0525        |\n",
            "|    n_updates            | 230           |\n",
            "|    policy_gradient_loss | -0.00384      |\n",
            "|    value_loss           | 6.01          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 482           |\n",
            "|    iterations           | 25            |\n",
            "|    time_elapsed         | 106           |\n",
            "|    total_timesteps      | 51200         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00035440686 |\n",
            "|    clip_fraction        | 0.000879      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.0204       |\n",
            "|    explained_variance   | 0.991         |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.0417        |\n",
            "|    n_updates            | 240           |\n",
            "|    policy_gradient_loss | -0.000309     |\n",
            "|    value_loss           | 0.2           |\n",
            "-------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 484        |\n",
            "|    iterations           | 26         |\n",
            "|    time_elapsed         | 109        |\n",
            "|    total_timesteps      | 53248      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.16492812 |\n",
            "|    clip_fraction        | 0.0609     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.105     |\n",
            "|    explained_variance   | 0.999      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | -0.0178    |\n",
            "|    n_updates            | 250        |\n",
            "|    policy_gradient_loss | -0.00557   |\n",
            "|    value_loss           | 0.0399     |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 483         |\n",
            "|    iterations           | 27          |\n",
            "|    time_elapsed         | 114         |\n",
            "|    total_timesteps      | 55296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008546018 |\n",
            "|    clip_fraction        | 0.0615      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.149      |\n",
            "|    explained_variance   | 0.626       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.33        |\n",
            "|    n_updates            | 260         |\n",
            "|    policy_gradient_loss | -0.00948    |\n",
            "|    value_loss           | 23.9        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 485        |\n",
            "|    iterations           | 28         |\n",
            "|    time_elapsed         | 118        |\n",
            "|    total_timesteps      | 57344      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.14919347 |\n",
            "|    clip_fraction        | 0.106      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.105     |\n",
            "|    explained_variance   | 0.741      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.65       |\n",
            "|    n_updates            | 270        |\n",
            "|    policy_gradient_loss | -0.0206    |\n",
            "|    value_loss           | 6.18       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 486        |\n",
            "|    iterations           | 29         |\n",
            "|    time_elapsed         | 122        |\n",
            "|    total_timesteps      | 59392      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.33131263 |\n",
            "|    clip_fraction        | 0.173      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.16      |\n",
            "|    explained_variance   | 0.114      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.9        |\n",
            "|    n_updates            | 280        |\n",
            "|    policy_gradient_loss | -0.0557    |\n",
            "|    value_loss           | 14.9       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 485        |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 126        |\n",
            "|    total_timesteps      | 61440      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.11427239 |\n",
            "|    clip_fraction        | 0.372      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.408     |\n",
            "|    explained_variance   | 0.331      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 7.42       |\n",
            "|    n_updates            | 290        |\n",
            "|    policy_gradient_loss | -0.0812    |\n",
            "|    value_loss           | 15.3       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 487        |\n",
            "|    iterations           | 31         |\n",
            "|    time_elapsed         | 130        |\n",
            "|    total_timesteps      | 63488      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06980764 |\n",
            "|    clip_fraction        | 0.165      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.147     |\n",
            "|    explained_variance   | 0.419      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 9.36       |\n",
            "|    n_updates            | 300        |\n",
            "|    policy_gradient_loss | -0.0524    |\n",
            "|    value_loss           | 15.3       |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 488          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 134          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0088388305 |\n",
            "|    clip_fraction        | 0.0487       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.0596      |\n",
            "|    explained_variance   | 0.568        |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.67         |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.0135      |\n",
            "|    value_loss           | 14           |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 487        |\n",
            "|    iterations           | 33         |\n",
            "|    time_elapsed         | 138        |\n",
            "|    total_timesteps      | 67584      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00283953 |\n",
            "|    clip_fraction        | 0.0315     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.0524    |\n",
            "|    explained_variance   | 0.757      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.1        |\n",
            "|    n_updates            | 320        |\n",
            "|    policy_gradient_loss | -0.00864   |\n",
            "|    value_loss           | 9.51       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                   |          |\n",
            "|    fps                  | 489      |\n",
            "|    iterations           | 34       |\n",
            "|    time_elapsed         | 142      |\n",
            "|    total_timesteps      | 69632    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 0.227209 |\n",
            "|    clip_fraction        | 0.047    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -0.0442  |\n",
            "|    explained_variance   | 0.895    |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 3.13     |\n",
            "|    n_updates            | 330      |\n",
            "|    policy_gradient_loss | 0.0424   |\n",
            "|    value_loss           | 5.05     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 490       |\n",
            "|    iterations           | 35        |\n",
            "|    time_elapsed         | 146       |\n",
            "|    total_timesteps      | 71680     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1.2562323 |\n",
            "|    clip_fraction        | 0.358     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.696    |\n",
            "|    explained_variance   | -1.61     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.128     |\n",
            "|    n_updates            | 340       |\n",
            "|    policy_gradient_loss | -0.0335   |\n",
            "|    value_loss           | 36        |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 489         |\n",
            "|    iterations           | 36          |\n",
            "|    time_elapsed         | 150         |\n",
            "|    total_timesteps      | 73728       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009215802 |\n",
            "|    clip_fraction        | 0.0631      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.057      |\n",
            "|    explained_variance   | 0.492       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 10.3        |\n",
            "|    n_updates            | 350         |\n",
            "|    policy_gradient_loss | -0.0236     |\n",
            "|    value_loss           | 20.7        |\n",
            "-----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                   |           |\n",
            "|    fps                  | 490       |\n",
            "|    iterations           | 37        |\n",
            "|    time_elapsed         | 154       |\n",
            "|    total_timesteps      | 75776     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1.1128141 |\n",
            "|    clip_fraction        | 0.0688    |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -0.00615  |\n",
            "|    explained_variance   | 0.799     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 8.86      |\n",
            "|    n_updates            | 360       |\n",
            "|    policy_gradient_loss | 2         |\n",
            "|    value_loss           | 14.8      |\n",
            "---------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 491           |\n",
            "|    iterations           | 38            |\n",
            "|    time_elapsed         | 158           |\n",
            "|    total_timesteps      | 77824         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00022821123 |\n",
            "|    clip_fraction        | 0.000439      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.000825     |\n",
            "|    explained_variance   | -0.477        |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.17          |\n",
            "|    n_updates            | 370           |\n",
            "|    policy_gradient_loss | -0.000533     |\n",
            "|    value_loss           | 25.2          |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 490           |\n",
            "|    iterations           | 39            |\n",
            "|    time_elapsed         | 162           |\n",
            "|    total_timesteps      | 79872         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.1117663e-08 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.00136      |\n",
            "|    explained_variance   | 0.477         |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.0159        |\n",
            "|    n_updates            | 380           |\n",
            "|    policy_gradient_loss | 6.28e-08      |\n",
            "|    value_loss           | 0.0216        |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 491           |\n",
            "|    iterations           | 40            |\n",
            "|    time_elapsed         | 166           |\n",
            "|    total_timesteps      | 81920         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00035678616 |\n",
            "|    clip_fraction        | 0.16          |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.125        |\n",
            "|    explained_variance   | 0.838         |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 0.0016        |\n",
            "|    n_updates            | 390           |\n",
            "|    policy_gradient_loss | 8.3e-05       |\n",
            "|    value_loss           | 0.931         |\n",
            "-------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 491        |\n",
            "|    iterations           | 41         |\n",
            "|    time_elapsed         | 170        |\n",
            "|    total_timesteps      | 83968      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.83962214 |\n",
            "|    clip_fraction        | 0.0405     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.0632    |\n",
            "|    explained_variance   | 0.858      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.00318    |\n",
            "|    n_updates            | 400        |\n",
            "|    policy_gradient_loss | -0.00141   |\n",
            "|    value_loss           | 0.933      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 483         |\n",
            "|    iterations           | 42          |\n",
            "|    time_elapsed         | 178         |\n",
            "|    total_timesteps      | 86016       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016625822 |\n",
            "|    clip_fraction        | 0.114       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.147      |\n",
            "|    explained_variance   | 0.483       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 14          |\n",
            "|    n_updates            | 410         |\n",
            "|    policy_gradient_loss | -0.0363     |\n",
            "|    value_loss           | 34.5        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 483         |\n",
            "|    iterations           | 43          |\n",
            "|    time_elapsed         | 182         |\n",
            "|    total_timesteps      | 88064       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009856626 |\n",
            "|    clip_fraction        | 0.0399      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.0691     |\n",
            "|    explained_variance   | 0.719       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.76        |\n",
            "|    n_updates            | 420         |\n",
            "|    policy_gradient_loss | -0.0294     |\n",
            "|    value_loss           | 20.9        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-253-b36bd0c61687>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'MlpPolicy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Create a PPO model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000000\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Train the model for 10000 timesteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/ppo/ppo.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    305\u001b[0m     ) -> SelfPPO:\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m         return super().learn(\n\u001b[0m\u001b[1;32m    308\u001b[0m             \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mcontinue_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_rollout_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcontinue_training\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/stable_baselines3/common/on_policy_algorithm.py\u001b[0m in \u001b[0;36mcollect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mterminal_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mrollout_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_obs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_episode_starts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_obs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_obs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_episode_starts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdones\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume you have a trained model called 'model' and a list of rides called 'rides'\n",
        "\n",
        "# Create a function to preprocess each observation (vector of data that contains important samples about the ride)\n",
        "def preprocess_observation(observation):\n",
        "    # Preprocess the observation as necessary (e.g., normalize, scale, one-hot encode, etc.)\n",
        "    preprocessed_observation = observation # placeholder\n",
        "    return preprocessed_observation\n",
        "\n",
        "# Create a list to hold the predicted actions for each observation\n",
        "predicted_actions = []\n",
        "\n",
        "# Iterate over each observation (vector of data that contains important samples about the ride)\n",
        "\n",
        "for observation in data.values:\n",
        "    # Preprocess the observation\n",
        "    preprocessed_observation = preprocess_observation(observation)\n",
        "\n",
        "    # Predict the action to take for this observation using the trained model\n",
        "    action, _ = model.predict(preprocessed_observation, deterministic=True)\n",
        "\n",
        "    # Add the predicted action to the list of predicted actions\n",
        "    predicted_actions.append(action)\n",
        "\n",
        "# Use the predicted actions to determine the order of the rides\n",
        "ordered_rides = [data.values[i] for i in np.argsort(predicted_actions)]\n",
        "\n",
        "ordered_rides = pd.DataFrame(ordered_rides, columns=['appt_hour', 'appt_minute', 'asset_id', 'dropoff_lat', 'dropoff_lng', 'load_order', 'multi_load_after', 'multi_load_before', 'pickup_hour', 'pickup_lat', 'pickup_lng', 'pickup_minute', 'rider_id', 'schedule_order', 'space_type'])\n",
        "ordered_rides.head(15)\n"
      ],
      "metadata": {
        "id": "T6hI6oNwiWbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model and visualize its decisions\n",
        "obs = env.reset()\n",
        "for i in range(1000):\n",
        "    action, _ = model.predict(obs, deterministic=True)\n",
        "    obs, reward, done, info = env.step(action)\n",
        "    env.render()\n",
        "    if done:\n",
        "        obs = env.reset()\n",
        "env.close()"
      ],
      "metadata": {
        "id": "DUXWCam-c_M9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}