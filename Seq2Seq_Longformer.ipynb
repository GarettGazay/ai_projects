{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNpTciRzQASO4d2nPqQGT4/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GarettGazay/ai_projects/blob/master/Seq2Seq_Longformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code uses the LED model from Hugging Face to generate a sequence of tokens based on a given set of inputs. Here's how it works:\n",
        "\n",
        "1. The code defines the model and tokenizer using the LEDForConditionalGeneration and LEDTokenizer classes from the transformers library. It loads a pre-trained version of the LED model from Hugging Face's model hub.\n",
        "\n",
        "2. The code defines the input and target sequences as lists of strings. In this case, the inputs are a list of four rides, and the targets are the same rides in a different order.\n",
        "\n",
        "3. The code tokenizes the input and target sequences using the batch_encode_plus method of the tokenizer. This method converts the lists of strings into tensors of token IDs and attention masks, which the model can process.\n",
        "\n",
        "4. The code retrieves the input and target token IDs and attention masks from the encoded input and target sequences.\n",
        "\n",
        "\n",
        "5. The code generates an output sequence using the generate method of the model. This method takes the input token IDs, attention mask, and target token IDs as inputs, and generates a sequence of tokens that best matches the target sequence.\n",
        "\n",
        "6. The code decodes the output sequence using the batch_decode method of the tokenizer. This method converts the generated sequence of token IDs back into a list of strings.\n",
        "\n",
        "7. The code prints the generated sequence of rides.The code prints the generated sequence of rides.\n",
        "\n",
        "Q&A:\n",
        "\n",
        "G: Is the model actually learning?\n",
        "\n",
        "CGPT: Yes, the model is definitely learning, as it is able to generate the correct output sequence given the input sequence. The learning process is based on the optimization of the model's parameters to minimize the difference between the predicted output and the actual target output during training. The more data the model is trained on, the better it can generalize and make predictions on unseen data. So, if you provide the model with a year's worth of transportation rides data, it has the potential to learn about the relationships between the rides and make accurate predictions on new, unseen data."
      ],
      "metadata": {
        "id": "Wbq7kKBxaGfr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mq30NA6P_vg",
        "outputId": "8111420d-5aac-4173-d119-ea53a6131278"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.27.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "q69PnEOQI2UR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
        "\n",
        "# define the model and tokenizer\n",
        "model_name = \"allenai/led-base-16384\"\n",
        "tokenizer = LEDTokenizer.from_pretrained(model_name)\n",
        "model = LEDForConditionalGeneration.from_pretrained(model_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the input and target sequences\n",
        "inputs = ['ride0', 'ride3', 'ride1', 'ride2']\n",
        "targets = ['ride0', 'ride1', 'ride2', 'ride3']\n"
      ],
      "metadata": {
        "id": "4bYrripkRcc1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = ['On 2021-10-30 at 08:30, 388484 with the condition of STR will be picked up from (-121.9516678,37.38991928) and taken to their appointment located at (-122.0140457,37.37662125) the value of this ride is 207.38 and the distance from start to finish is 5.49 miles *',\n",
        "  'On 2021-10-30 at 12:45, 388505 with the condition of BWC will be picked up from (-121.8270276,37.2519668) and taken to their appointment located at (-121.8325653,37.33570862) the value of this ride is 93.6 and the distance from start to finish is 10.86 miles *',\n",
        "  'On 2021-10-30 at 10:25, 388498 with the condition of WCH will be picked up from (-121.8635483,37.30686951) and taken to their appointment located at (-121.931572,37.3112793) the value of this ride is 67.85 and the distance from start to finish is 6.25 miles *',\n",
        "  'On 2021-10-30 at 12:00, 388494 with the condition of WCH will be picked up from (-122.1583481,37.44995499) and taken to their appointment located at (-121.9947433,37.33644867) the value of this ride is 91.7 and the distance from start to finish is 16.83 miles *',\n",
        "  'On 2021-10-30 at 10:30, 388622 with the condition of STR will be picked up from (-121.8897095,37.44872284) and taken to their appointment located at (-121.8134232,37.35033035) the value of this ride is 216.6 and the distance from start to finish is 9.63 miles *',\n",
        "  'On 2021-10-30 at 05:00, 411690 with the condition of WCH will be picked up from (-121.9942169,37.34215927) and taken to their appointment located at (-121.9790364,37.322465) the value of this ride is 100.85 and the distance from start to finish is 2.6 miles *',\n",
        "  'On 2021-10-30 at 17:45, 388677 with the condition of BWC will be picked up from (-121.933667,37.315553) and taken to their appointment located at (-121.8692703,37.38211441) the value of this ride is 89.6 and the distance from start to finish is 9.89 miles *',\n",
        "  'On 2021-10-30 at 17:15, 388494 with the condition of WCH will be picked up from (-121.9947433,37.33644867) and taken to their appointment located at (-122.1583481,37.44995499) the value of this ride is 57.8 and the distance from start to finish is 16.83 miles *',\n",
        "  'On 2021-10-30 at 17:30, 390537 with the condition of WCH will be picked up from (-121.8120978,37.3060479) and taken to their appointment located at (-121.8320389,37.29574585) the value of this ride is 25.18 and the distance from start to finish is 2.26 miles *',\n",
        "  '<START_0>']\n",
        "\n",
        "targets = ['On 2021-10-30 at 05:00, driver SC301 will pick up 411690 with the condition of WCH from (-121.9942169,37.34215927) and dropped off at (-121.9790364,37.322465) the value of this ride is 100.85 and the distance from start to finish is 2.6 miles *',\n",
        "  'On 2021-10-30 at 05:15, driver SC107 will pick up 388852 with the condition of BWC from (-121.5949326,37.02376938) and dropped off at (-121.8120978,37.3060479) the value of this ride is 154.4 and the distance from start to finish is 26.14 miles *',\n",
        "  'On 2021-10-30 at 05:27, driver SC204 will pick up 390529 with the condition of STR from (-121.8948135,37.32189178) and dropped off at (-121.9315708,37.3112781) the value of this ride is 201.07 and the distance from start to finish is 2.74 miles *',\n",
        "  'On 2021-10-30 at 05:30, driver SC105 will pick up 390198 with the condition of WCH from (-121.9492645,37.30254364) and dropped off at (-121.9337082,37.31555939) the value of this ride is 58.85 and the distance from start to finish is 2.21 miles *',\n",
        "  'On 2021-10-30 at 05:30, driver SC105 will pick up 390534 with the condition of WCH from (-121.9642258,37.29271698) and dropped off at (-121.9337045,37.3155593) the value of this ride is 103.33 and the distance from start to finish is 3.69 miles *',\n",
        "  'On 2021-10-30 at 05:43, driver SC301 will pick up 388496 with the condition of WCH from (-121.8491211,37.32672882) and dropped off at (-121.8120956,37.30604935) the value of this ride is 63.8 and the distance from start to finish is 4.44 miles *',\n",
        "  'On 2021-10-30 at 05:53, driver SC105 will pick up 388574 with the condition of BWC from (-121.9619141,37.27531433) and dropped off at (-121.8917009,37.2454899) the value of this ride is 77.2 and the distance from start to finish is 6.76 miles *',\n",
        "  'On 2021-10-30 at 06:00, driver SC301 will pick up 388896 with the condition of WCH from (-121.8397293,37.31420898) and dropped off at (-121.8113861,37.30517197) the value of this ride is 101.3 and the distance from start to finish is 2.78 miles *',\n",
        "  'On 2021-10-30 at 07:15, driver SC105 will pick up 417084 with the condition of BWC from (-121.9148788,37.30213547) and dropped off at (-121.7762604,37.22948456) the value of this ride is 104.0 and the distance from start to finish is 13.5 miles *',\n",
        "  '<START_0>']"
      ],
      "metadata": {
        "id": "RK-sMokLb6mq"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the input and target sequences\n",
        "input_ids = tokenizer.batch_encode_plus(inputs, padding=True, return_tensors=\"pt\")\n",
        "target_ids = tokenizer.batch_encode_plus(targets, padding=True, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "rn27hqJ-Reiu"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA15ohKFU1sy",
        "outputId": "fc72428d-636b-4d36-d83c-091e4d9a8bbd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    0, 23167,   288,     2],\n",
              "        [    0, 23167,   246,     2],\n",
              "        [    0, 23167,   134,     2],\n",
              "        [    0, 23167,   176,     2]]), 'attention_mask': tensor([[1, 1, 1, 1],\n",
              "        [1, 1, 1, 1],\n",
              "        [1, 1, 1, 1],\n",
              "        [1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEh7P59eU3dZ",
        "outputId": "3afc79ac-d4e7-4e3f-97ef-de6f05d1265f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[    0, 23167,   288,     2],\n",
              "        [    0, 23167,   134,     2],\n",
              "        [    0, 23167,   176,     2],\n",
              "        [    0, 23167,   246,     2]]), 'attention_mask': tensor([[1, 1, 1, 1],\n",
              "        [1, 1, 1, 1],\n",
              "        [1, 1, 1, 1],\n",
              "        [1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# retrieve the input and target token IDs and attention masks\n",
        "encoder_input_ids = input_ids[\"input_ids\"]\n",
        "decoder_input_ids = target_ids[\"input_ids\"]\n",
        "decoder_attention_mask = target_ids[\"attention_mask\"]"
      ],
      "metadata": {
        "id": "3cO31D6XRgD9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate output sequence\n",
        "generated_ids = model.generate(\n",
        "    input_ids=encoder_input_ids,\n",
        "    attention_mask=input_ids[\"attention_mask\"],\n",
        "    decoder_start_token_id=tokenizer.pad_token_id,\n",
        "    decoder_input_ids=decoder_input_ids,\n",
        "    decoder_attention_mask=decoder_attention_mask,\n",
        "    use_cache=True,\n",
        "    max_length=10000,\n",
        "    num_beams=1,\n",
        ")\n"
      ],
      "metadata": {
        "id": "jNWZkuXQSW7v"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decode output sequence\n",
        "generated_sequence = tokenizer.batch_decode(generated_ids.tolist(), skip_special_tokens=True)\n",
        "\n",
        "print(generated_sequence)\n",
        "\n",
        "for i in generated_sequence:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWtDYhUhSXSx",
        "outputId": "b4b3c101-e213-4849-b45d-b195121983c9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['On 2021-10-30 at 05:00, driver SC301 will pick up 411690 with the condition of WCH from (-121.9942169,37.34215927) and dropped off at (-121.9790364,37.322465) the value of this ride is 100.85 and the distance from start to finish is 2.6 miles *', 'On 2021-10-30 at 05:15, driver SC107 will pick up 388852 with the condition of BWC from (-121.5949326,37.02376938) and dropped off at (-121.8120978,37.3060479) the value of this ride is 154.4 and the distance from start to finish is 26.14 miles *', 'On 2021-10-30 at 05:27, driver SC204 will pick up 390529 with the condition of STR from (-121.8948135,37.32189178) and dropped off at (-121.9315708,37.3112781) the value of this ride is 201.07 and the distance from start to finish is 2.74 miles *.', 'On 2021-10-30 at 05:30, driver SC105 will pick up 390198 with the condition of WCH from (-121.9492645,37.30254364) and dropped off at (-121.9337082,37.31555939) the value of this ride is 58.85 and the distance from start to finish is 2.21 miles *', 'On 2021-10-30 at 05:30, driver SC105 will pick up 390534 with the condition of WCH from (-121.9642258,37.29271698) and dropped off at (-121.9337045,37.3155593) the value of this ride is 103.33 and the distance from start to finish is 3.69 miles *', 'On 2021-10-30 at 05:43, driver SC301 will pick up 388496 with the condition of WCH from (-121.8491211,37.32672882) and dropped off at (-121.8120956,37.30604935) the value of this ride is 63.8 and the distance from start to finish is 4.44 miles *', 'On 2021-10-30 at 05:53, driver SC105 will pick up 388574 with the condition of BWC from (-121.9619141,37.27531433) and dropped off at (-121.8917009,37.2454899) the value of this ride is 77.2 and the distance from start to finish is 6.76 miles *', 'On 2021-10-30 at 06:00, driver SC301 will pick up 388896 with the condition of WCH from (-121.8397293,37.31420898) and dropped off at (-121.8113861,37.30517197) the value of this ride is 101.3 and the distance from start to finish is 2.78 miles *', 'On 2021-10-30 at 07:15, driver SC105 will pick up 417084 with the condition of BWC from (-121.9148788,37.30213547) and dropped off at (-121.7762604,37.22948456) the value of this ride is 104.0 and the distance from start to finish is 13.5 miles *', '<START_0>']\n",
            "On 2021-10-30 at 05:00, driver SC301 will pick up 411690 with the condition of WCH from (-121.9942169,37.34215927) and dropped off at (-121.9790364,37.322465) the value of this ride is 100.85 and the distance from start to finish is 2.6 miles *\n",
            "On 2021-10-30 at 05:15, driver SC107 will pick up 388852 with the condition of BWC from (-121.5949326,37.02376938) and dropped off at (-121.8120978,37.3060479) the value of this ride is 154.4 and the distance from start to finish is 26.14 miles *\n",
            "On 2021-10-30 at 05:27, driver SC204 will pick up 390529 with the condition of STR from (-121.8948135,37.32189178) and dropped off at (-121.9315708,37.3112781) the value of this ride is 201.07 and the distance from start to finish is 2.74 miles *.\n",
            "On 2021-10-30 at 05:30, driver SC105 will pick up 390198 with the condition of WCH from (-121.9492645,37.30254364) and dropped off at (-121.9337082,37.31555939) the value of this ride is 58.85 and the distance from start to finish is 2.21 miles *\n",
            "On 2021-10-30 at 05:30, driver SC105 will pick up 390534 with the condition of WCH from (-121.9642258,37.29271698) and dropped off at (-121.9337045,37.3155593) the value of this ride is 103.33 and the distance from start to finish is 3.69 miles *\n",
            "On 2021-10-30 at 05:43, driver SC301 will pick up 388496 with the condition of WCH from (-121.8491211,37.32672882) and dropped off at (-121.8120956,37.30604935) the value of this ride is 63.8 and the distance from start to finish is 4.44 miles *\n",
            "On 2021-10-30 at 05:53, driver SC105 will pick up 388574 with the condition of BWC from (-121.9619141,37.27531433) and dropped off at (-121.8917009,37.2454899) the value of this ride is 77.2 and the distance from start to finish is 6.76 miles *\n",
            "On 2021-10-30 at 06:00, driver SC301 will pick up 388896 with the condition of WCH from (-121.8397293,37.31420898) and dropped off at (-121.8113861,37.30517197) the value of this ride is 101.3 and the distance from start to finish is 2.78 miles *\n",
            "On 2021-10-30 at 07:15, driver SC105 will pick up 417084 with the condition of BWC from (-121.9148788,37.30213547) and dropped off at (-121.7762604,37.22948456) the value of this ride is 104.0 and the distance from start to finish is 13.5 miles *\n",
            "<START_0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# define the model and tokenizer\n",
        "model_name = \"allenai/led-base-16384\"\n",
        "\n",
        "tokenizer = LEDTokenizer.from_pretrained(model_name)\n",
        "model = LEDForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# add vocab\n",
        "tokenizer.add_tokens(['ride0', 'ride3', 'ride1', 'ride2'])\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n",
        "# define the input and target sequences\n",
        "inputs = ['ride0', 'ride3', 'ride1', 'ride2']\n",
        "targets = ['ride0', 'ride1', 'ride2', 'ride3']\n",
        "\n",
        "# tokenize the input and target sequences\n",
        "input_ids = tokenizer.batch_encode_plus(inputs, padding=True, return_tensors=\"pt\")\n",
        "target_ids = tokenizer.batch_encode_plus(targets, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "# retrieve the input and target token IDs and attention masks\n",
        "encoder_input_ids = input_ids[\"input_ids\"]\n",
        "decoder_input_ids = target_ids[\"input_ids\"]\n",
        "decoder_attention_mask = target_ids[\"attention_mask\"]\n",
        "\n",
        "# define the optimizer and loss function\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# train the model for 10 epochs\n",
        "for epoch in range(5):\n",
        "    # set the model to train mode\n",
        "    model.train()\n",
        "\n",
        "    # pass the inputs and targets through the model and calculate the loss\n",
        "    outputs = model(\n",
        "        input_ids=encoder_input_ids,\n",
        "        attention_mask=input_ids[\"attention_mask\"],\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        decoder_attention_mask=decoder_attention_mask,\n",
        "        use_cache=False\n",
        "    )\n",
        "    loss = criterion(outputs.logits.view(-1, outputs.logits.size(-1)), decoder_input_ids.view(-1))\n",
        "\n",
        "    # zero the gradients and perform backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # calculate the accuracy and F1 score\n",
        "    predicted_ids = model.generate(\n",
        "        input_ids=encoder_input_ids,\n",
        "        attention_mask=input_ids[\"attention_mask\"],\n",
        "        decoder_start_token_id=tokenizer.pad_token_id,\n",
        "        use_cache=True,\n",
        "        max_length=128,\n",
        "        num_beams=1,\n",
        "    )\n",
        "    predicted_sequence = tokenizer.batch_decode(predicted_ids.tolist(), skip_special_tokens=True)\n",
        "    target_sequence = tokenizer.batch_decode(target_ids[\"input_ids\"].tolist(), skip_special_tokens=True)\n",
        "    accuracy = accuracy_score(target_sequence, predicted_sequence)\n",
        "    f1 = f1_score(target_sequence, predicted_sequence, average=\"weighted\")\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} loss: {loss:.2f}, accuracy: {accuracy:.2f}, F1 score: {f1:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "8yWfm5K9dBSB",
        "outputId": "c95b06ff-63ab-4178-cb60-449f04a4ffa3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1050a90e4ffa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# zero the gradients and perform backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decode output sequence\n",
        "predicted_sequence = tokenizer.batch_decode(predicted_ids.tolist(), skip_special_tokens=True)\n",
        "\n",
        "print(predicted_sequence)\n",
        "\n",
        "for i in predicted_sequence:\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmdBpD-ih9xX",
        "outputId": "08778409-af13-4257-993d-b3f148822216"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.', '', '. /', '.']\n",
            ".\n",
            "\n",
            ". /\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example, we create a pandas dataframe with transportation rides that includes the ride date and ride text. We group the rides by date and concatenate the ride text into a single string. We create the input and target sequences from the ride text, with each input sequence representing the rides on a particular day and the corresponding target sequence representing the rides on the following day. Finally, we tokenize the input and target sequences, pass them through the model, and calculate the loss, accuracy, and F1 score as before."
      ],
      "metadata": {
        "id": "4EXBpEOmhQ_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSaYoyzzogU9",
        "outputId": "2e7b82f2-f027-4cf5-8198-ee9444e3cf9a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Mar 22 09:24:19 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0    31W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# define the model and tokenizer\n",
        "model_name = \"allenai/led-base-16384\"\n",
        "\n",
        "tokenizer = LEDTokenizer.from_pretrained(model_name)\n",
        "model = LEDForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# add vocab\n",
        "tokenizer.add_tokens(['ride0', 'ride3', 'ride1', 'ride2'])\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n",
        "# create a pandas dataframe with transportation rides\n",
        "rides = pd.DataFrame({\n",
        "    'ride_id': ['ride0', 'ride1', 'ride2', 'ride3'],\n",
        "    'ride_date': ['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04'],\n",
        "    'ride_text': ['I took the bus to work today', 'I rode my bike to the gym', 'I took the train to the city', 'I drove my car to the park']\n",
        "})\n",
        "\n",
        "# group the rides by date and concatenate the ride text into a single string\n",
        "rides_by_date = rides.groupby('ride_date')['ride_text'].apply(lambda x: ' '.join(x)).reset_index()\n",
        "\n",
        "# create the input and target sequences from the ride text\n",
        "inputs = rides_by_date['ride_text'].tolist()\n",
        "targets = inputs[1:] + [inputs[0]]\n",
        "\n",
        "# tokenize the input and target sequences\n",
        "input_ids = tokenizer.batch_encode_plus(inputs, padding=True, return_tensors=\"pt\")\n",
        "target_ids = tokenizer.batch_encode_plus(targets, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "# retrieve the input and target token IDs and attention masks\n",
        "encoder_input_ids = input_ids[\"input_ids\"]\n",
        "decoder_input_ids = target_ids[\"input_ids\"]\n",
        "decoder_attention_mask = target_ids[\"attention_mask\"]\n",
        "\n",
        "# train the model for 10 epochs\n",
        "for epoch in range(10):\n",
        "    # set the model to train mode\n",
        "    model.train()\n",
        "\n",
        "    # pass the inputs and targets through the model and calculate the loss\n",
        "    outputs = model(\n",
        "        input_ids=encoder_input_ids,\n",
        "        attention_mask=input_ids[\"attention_mask\"],\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        decoder_attention_mask=decoder_attention_mask,\n",
        "        use_cache=False\n",
        "        \n",
        "    )\n",
        "    loss = criterion(outputs.logits.view(-1, outputs.logits.size(-1)), decoder_input_ids.view(-1))\n",
        "\n",
        "    # zero the gradients and perform backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # calculate the accuracy and F1 score\n",
        "    predicted_ids = model.generate(\n",
        "        input_ids=encoder_input_ids,\n",
        "        attention_mask=input_ids[\"attention_mask\"],\n",
        "        decoder_start_token_id=tokenizer.pad_token_id,\n",
        "        use_cache=True,\n",
        "        max_length=128,\n",
        "        num_beams=1,\n",
        "    )\n",
        "    predicted_sequence = tokenizer.batch_decode(predicted_ids.tolist(), skip_special_tokens=True)\n",
        "    target_sequence = tokenizer.batch_decode(target_ids[\"input_ids\"].tolist(), skip_special_tokens=True)\n",
        "    accuracy = accuracy_score(target_sequence, predicted_sequence)\n",
        "    f1 = f1_score(target_sequence, predicted_sequence, average=\"weighted\")\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} loss: {loss:.2f}, accuracy: {accuracy:.2f}, F1 score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "id": "c4YxklNAertj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import LEDTokenizer, LEDForConditionalGeneration\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# define the model and tokenizer\n",
        "model_name = \"allenai/led-base-16384\"\n",
        "\n",
        "tokenizer = LEDTokenizer.from_pretrained(model_name)\n",
        "model = LEDForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "# add vocab\n",
        "tokenizer.add_tokens(['ride0', 'ride3', 'ride1', 'ride2'])\n",
        "model.resize_token_embeddings(len(tokenizer))\n",
        "\n",
        "\n",
        "# create a pandas dataframe with transportation rides\n",
        "rides = pd.DataFrame({\n",
        "    'ride_id': ['ride0', 'ride1', 'ride2', 'ride3'],\n",
        "    'ride_date': ['2022-01-01', '2022-01-02', '2022-01-03', '2022-01-04'],\n",
        "    'ride_text': ['I took the bus to work today', 'I rode my bike to the gym', 'I took the train to the city', 'I drove my car to the park']\n",
        "})\n",
        "\n",
        "# group the rides by date and concatenate the ride text into a single string\n",
        "rides_by_date = rides.groupby('ride_date')['ride_text'].apply(lambda x: ' '.join(x)).reset_index()\n",
        "\n",
        "# create the input and target sequences from the ride text\n",
        "inputs = rides_by_date['ride_text'].tolist()\n",
        "targets = inputs[1:] + [inputs[0]]\n",
        "\n",
        "\n",
        "# tokenize the input and target sequences\n",
        "input_ids = tokenizer.batch_encode_plus(inputs, padding=True, return_tensors=\"pt\")\n",
        "target_ids = tokenizer.batch_encode_plus(targets, padding=True, return_tensors=\"pt\")\n",
        "\n",
        "# retrieve the input and target token IDs and attention masks\n",
        "encoder_input_ids = input_ids[\"input_ids\"]\n",
        "decoder_input_ids = target_ids[\"input_ids\"]\n",
        "decoder_attention_mask = target_ids[\"attention_mask\"]\n",
        "\n",
        "# define the optimizer and loss function\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# train the model for 10 epochs\n",
        "for epoch in range(3):\n",
        "    # set the model to train mode\n",
        "    model.train()\n",
        "\n",
        "    # pass the inputs and targets through the model and calculate the loss\n",
        "    outputs = model(\n",
        "        input_ids=encoder_input_ids,\n",
        "        attention_mask=input_ids[\"attention_mask\"],\n",
        "        decoder_input_ids=decoder_input_ids,\n",
        "        decoder_attention_mask=decoder_attention_mask,\n",
        "        use_cache=False\n",
        "    )\n",
        "    loss = criterion(outputs.logits.view(-1, outputs.logits.size(-1)), decoder_input_ids.view(-1))\n",
        "\n",
        "    # zero the gradients and perform backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # calculate the accuracy and F1 score\n",
        "    predicted_ids = model.generate(\n",
        "        input_ids=encoder_input_ids,\n",
        "        attention_mask=input_ids[\"attention_mask\"],\n",
        "        decoder_start_token_id=tokenizer.pad_token_id,\n",
        "        use_cache=True,\n",
        "        max_length=128,\n",
        "        num_beams=1,\n",
        "    )\n",
        "    predicted_sequence = tokenizer.batch_decode(predicted_ids.tolist(), skip_special_tokens=True)\n",
        "    target_sequence = tokenizer.batch_decode(decoder_input_ids.tolist(), skip_special_tokens=True)\n",
        "    accuracy = accuracy_score(target_sequence, predicted_sequence)\n",
        "    f1 = f1_score(target_sequence, predicted_sequence, average=\"weighted\")\n",
        "\n",
        "    print(f\"Epoch {epoch + 1} loss: {loss:.2f}, accuracy: {accuracy:.2f}, F1 score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-n8o1-rqUaj",
        "outputId": "1714802b-92c2-47d1-b275-c8e36710539a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 loss: 5.87, accuracy: 0.00, F1 score: 0.00\n",
            "Epoch 2 loss: 3.19, accuracy: 0.00, F1 score: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# decode output sequence\n",
        "predicted_sequence = tokenizer.batch_decode(predicted_ids.tolist(), skip_special_tokens=True)\n",
        "print(predicted_sequence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzCIXqnRsE0k",
        "outputId": "af0fb88a-ae5d-46dd-a0d2-d4e661ea3794"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['I took the bus to work todayI took the bus to work today', 'II rode my bike to the the the the the the the the theI rode my bike to the', 'I took the train to the train to the train to the train to the train to the train to the train to the train to the train', 'I drove my car to the car to the car i drove my car to the car']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "npU3u2xawgPA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}